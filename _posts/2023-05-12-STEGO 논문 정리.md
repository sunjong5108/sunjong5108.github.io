---
key: jekyll-text-theme
title: STEGO 논문 정리'
excerpt: 'STEGO 논문 읽고 정리하기'
tags: [AI, Computer Vision, Paper, Self-supervised learning, Pre-training, ViT, Unsupervised semantic segmentation]
---

# Unsupervised Semantic Segmentation By Distilling Feature Correspondences (ICLR 2022)

## Abstract

- Unsupervised Semantic Segmentation의 목적? <br/>
  → 이를 위해, 알고리즘이 모든 픽셀에 대해 의미론적으로 의미있고 뚜렷한 cluster를 생성할 만큼 compact한 feature 생성해야함
- 저자들 cluster compactification으로부터 feature learning 분리<br/>
  → 현재 unsupervised feature learning frameworks는 이미 correlation들이 의미적으로 일관성있는 dense feature들을 생성함<br/>
  <span style='color:red'>→ 이런 관측사실에 영감을 받아 unsupervised feature들을 high-quality discrete semantic label들로 distill하는 framework 제안 (**S**elf-supervised **T**ransformer with **E**nergy-based **G**raph **O**ptimization; **STEGO**)</span> <br/>
  → STEGO, copora에 걸쳐 relationship을 보존하면서 feature들을 compact한 cluster들이 되도록 만들어주는 새로운 Contrastive function이 핵심


---

## Introduction

- 저자들
  - Unsupervised feature learning framework로부터의 pre-trained feature들 활용 <br/>
    $+$ 이 pre-trained feature를 image corpora에 걸쳐 relationship를 보존하면서 compact하고 뚜렷한 structure로 distill하는 것에 초점 (STEGO) <br/>
    <span style='color:red'>→ DINO에서 학습한 것과 같은 unsupervised features 간의 상관관계가 동일한 이미지 내에서나 이미지 collection 전반에 걸처 이미 의미론적으로 일관성이 있다는 관찰에 기반</span>
    $+$ 새로운 Contrastive loss → pretrained unsupervised visual feature를 semantic cluster로 distill


---

## Related works

- Contrastive learning → image augmentation operation의 set에서 visual feature가 변하지 않는다고 가정

  - 이미지와 augmented 이미지 간의 feature similarity를 최대한하는 동시에 무작위로 sampling된 이미지 (negative sample) 간의 similarity 최소화 <br/>
    <span style='color:red'>negative sample은 많은 연구에서 중요하다고 강조함</span>

- 최근 , 이미지당 단일 global vector가 아닌 공간적으로 밀도가 높은 (dense한) feature map 생성이 목표

  - VADeR, Contrastive learning을 위해 positive pair로 작용하는 pixel간 알려진 correspondence를 유도하는 이미지 변환의 무작위 구성을 기반으로 pixel 별 local feature를 대조

- DINO, exponential moving average update로 self-distillation 수행하는 self-supervised learning framework

  - DINO의 class-attention → localize되고 semantic하게 의미있는 salient (두드러진) object segmentation을 생성할 수 있음
  - 저자들은 DINO의 feature가 salient object를 감지할 뿐만 아니라 이미지간 조밀(dense)하고 semantic하게 의미있는 correspondence를 추출하는데 사용할 수 있음을 보여줌

  - STEGO에서 DINO의 features (pretrained features) 이용해 clustering시 semantic segmentation 예측

---

## Method

### Feature Correspondence Predict Class Co-Occurrence

- Self-supervised visual feature learning
  - intermediate dense features가 의미적으로 관련성이 있음<br/>
    <span style='color:red'>intermediate dense features 활용하기 위해 dense feature map간의 "correlation volume"에 초점 <br/>→ convolution 또는 transformer architecture의 경우, dense feature map=특정 layer의 activation map<br/>$+$ transformer의 Q, K, V 행렬 → dense feature map의 후보가 될 수 있지만 성능이 좋지 않음</span>

-  feature correspondence tensor<br/>$$ F_{hwij} := \sum_c \dfrac{f_{chw}}{|f_{hw}|}\dfrac{g_{cij}}{|g_{ij}|}$$, (1)

  - 2가지 다른 image들에 대한 feature tensors $f \in \mathbb R^{CHW}$, $g\in \mathbb R^{CIJ}$<br/>여기서 $C$→ Channel dimension, $(H, W), (I, J)$ → Spatial dimension
  - (1)은 feature tensor $f$의 spatial position $(h, w)$에서의 feature와 $g$의 spatial position $(i, j)$에서의 feature 사이의 cosine similarity를 나타냄
  - $f=g$인 특별한 경우에 correspondence는 같은 이미지의 두 영역 사이의 similarity로 측정
  - <span style='color:red'>"cost-volume", Contrarstive architecture와 visual search engine에 대한 class Activation Map의 higher-order generlization 역할을 함</span>

  ![image](https://github.com/sunjong5108/CAM-based_Flare_Removal_Network/assets/81843626/95522b21-89a5-43e8-b1ce-5bd0291b7998)

- $(h, w)$에서 correspondence tensor $F$가 featurizer에 따라 어떻게 관련되는지 시각화 (Fig. 2)

  - Fig. 2는 DINO 기준으로 이미지 내 관련 semantic area 및 K-nearest neighbor가 서로 어떻게 대응되는지 표현

-   feature correspondence tensor

  - true label co-occurrence tensor와 강한 상관관곅 있음<br/><span style='color:red'>→특히 ground-truth semantic segmentation label $k \in C^{HW}, l \in C^{IJ}$ 쌍이 주어졌을때 ground-truth label co-occurrence tensor를 만들 수 있음</span>
  
  - $$L_{hwij}:= \begin{cases} 1, &\text{if $l_{hw} = k_{ij}$}\\ 0, &\text{if $l_{hw} \neq k_{ij}$} \end{cases}$$
    <span style='color:red'>→ 2가지 다른 이미지들 ($l, k$)에 대한 ground-truth semantic segmentation labels</span>
  
    - feature correspondences ($F$)가 ground-truth label co-occurrences ($L$)을 얼마나 잘 예측하는지 조사
      → feature가 semantic segmentation label가 얼마나 잘 일치하는지 측정 가능
      어떻게?? feature correspondences을 probability logit으로 처리, $L$에 대한 classifier로 사용시 average precision 계산
  
    - 저자들이 제안하는 STEGO가 AP성능 제일 좋음
      ![image](https://github.com/sunjong5108/CAM-based_Flare_Removal_Network/assets/81843626/70b214aa-7fe2-4f02-beae-92aa7f8341fe)
  
    - #### <span style='color:red'>흥미로운 점</span>
  
      - STEGO가 학습한 suprevisory signal 보다 더 나은 label predictor 라는 점
        <span style='color:blue'>왜? distillation precess가 supervisory signal 증폭하고 전체 dataset에 일관성 부여하기 때문</span>
        $ +$ STEGO의 parameter를 조정하기 위해 ground truth label 사용 X


### Distilling Feature Correspondences

- feature correspondences → unsupervised segmentation을 위한 signal 학습에 도움
  → 이 signal 활용, clutstering 시 고품질의 semantic segmentation을 생성 (pixel-wise embeddings)
  <span style='color:red'>어떻게 학습? feature correspondence를 'distill'하는 low-dimensional embedding을 학습</span>

  - 이를 위해, 방향이 없는 graphic model을 사용, noise가 있거나, 해상도가 낮은 clsass의 예측을 원본 이미지의 가장자리 및 color-correlated region에 정렬하여 개선하는 CRF에서 영감을 얻음

- $ N: \mathbb R^{C'H'W'} \rightarrow \mathbb R^{CHW}$

  - $N$: deep neural network backbone
  - 채널이 $C'$이고, spatial dimension이 $(H', W')$인 이미지 $x \rightarrow$ 채널이 C이고 spatial dimension이 $(H, W)$인 feature tensor $f$

- STEGO

  - backbone network frozen, light-weight segmentation head $\mathcal S:\mathbb R^{CHW} \rightarrow \mathbb R^{KHW}$ 학습에 초점
  - $\mathcal S$는 feature space를 $K$ dimension의 code space로 mapping ($K < C$)
    <span style='color:red'>$\mathcal S$의 목적? nonlinear projection 학습, $\mathcal S(f) =: s \in \mathbb R^{KHW} \Rightarrow$ compact clurster들을 형성허고, $f$의 correlation pattern 증폭</span>

- loss function

  -  image $x, y$ 쌍에서의 feature tensors → $f, g$
  - $f, g$의 segmentation features
    $s:=\mathcal S(f) \in \mathbb R^{CHW}$
    $s:=\mathcal S(g) \in \mathbb R^{CIJ}$
  - 식 (1)을 사용해서 $f$와 $g$ 그리고 $s$와 $t$로부터의 segmentation correlation tensor $\mathcal S \in R^{HWIJ}$ 로부터 feature correlation tensor $F \in R^{HWIJ}$ 계산
  - loss function의 목적
    - $f$와 $g$ 사이의 중요한 결합이 있으면 $s$와 $t$를 함께 push(?)하는 것


  ![image](https://github.com/sunjong5108/CAM-based_Flare_Removal_Network/assets/81843626/7166e390-87c3-4d09-985b-6ad3b539e4bc)

  - 그림 4에서처럼, loss function의 목적을 tensor $F$와 $S$의 simple element-wise multiplication으로 달성함
  - $$ \mathcal L_{simple-corr}(x, y, b):=-\sum_{hwij}(F_{hwij}-b)S_{hwij}$$, (2)
    $b$: collapse 방지하기 위해 uniform "negative pressure"를 식에 더해주는 hyper-parameter

- 식 (2): $S$에 대해서 $\mathcal L$를 최소화 <span style='color:red'>(★ $F$는 학습안함!)</span> 

  - $F-b > 0$ (positive)
    $S$를 크게
  - $F-b < 0$ (negative)
    $S$를 작게
  - <span style='color:red'>$F$와 $S$는 cosine similarity
    </span>
    <span style='color:red'>feature correspondences에 비례하는 강도를 갖는 segmentation features의 쌍에서 끌어들이거나 반발하는 힘을 발휘 </span>
  -  결론: $S$와 $F$와 같도록 권장하는 것이 아닌 $F-b$부호에 따라 전체 반정렬 (-1) 또는 정렬로 push됨

- **그런데** $\mathcal L_{simple-corr}$는 unstable, optimization을 위한 learning signal이 충분히 제공 X

  - **왜?** 해당 feature들이 서로 상관관계가 없을 때 segmentation feature을 전체 반정렬로 최적화하면 공선형성 (co-linearity)가 증가 $\Rightarrow$ **불안정성 초래**

    - <span style='color:blue'>* 공선형성: 독립변수 간 선형독립이 아닌 경우 $\rightarrow$ 독립변수 간 선형관계가 높다는 전체가 무너짐</span>

    <span style='color:red'>$\rightarrow$ 이를 방지하기 위해 상관관계가 약한 segmentation feature는 서로 직교가 되도록 최적화 $\Rightarrow$ 상관관계가 약한 변수를 완전 독립으로 만들어주는 것, 두 변수(벡터)의 내적을 0으로 만들어줌</span>

    <span style='color:red'>$\rightarrow$ segmentation correspondence $S$를 0으로 고정함으로써 효율적으로 달성할 수 있음 $\Rightarrow$ 최적화 안정성 ↑</span>

-  $+$ 상관관계 패턴이 집중된 작은 물체에 대한 learning signal의 균형을 맞출 때 문제 발생

  - 대부분의 위치에서 $F_{hwij}-b$는 음수이며, loss는 feature를 집계하지 않고 분산되도록 유도함
    <span style='color:red'>$\rightarrow$ negative! 서로 반발하는 힘이 커짐</span>
  - 그래서 최적화의 균형을 맞추기 위해 feature correspondence에 spatial centering operation을 도입
    $$F_{hwij}^{SC}:=F_{hwij} - \dfrac{1}{IJ}\sum_{i'j'}F_{hwi'j'}$$, (3)
    <span style='color:red'>$\rightarrow$ 분산되지 않도록 $i',j'$에 모아주는 작업</span>

- zero clamping으로 최종 loss 식
  $$\mathcal L_{corr}(x, y, b):=-\sum_{hwij}(F_{hwij}^{SC}-b)max(S_{hwij}, 0)$$, (4)

![image](https://github.com/sunjong5108/CAM-based_Flare_Removal_Network/assets/81843626/b4846e3b-b9b4-4a28-8a1f-68f54bbd8306)


### STEGO Architecture

![image](https://github.com/sunjong5108/CAM-based_Flare_Removal_Network/assets/81843626/7166e390-87c3-4d09-985b-6ad3b539e4bc)

-  식 (4), correspondence loss가 3개

   1) image와 같은 image 사이의 feature relationship을 distill하기 위한 segmentation head 학습 (self corr.)
   2) image와 그 image의 KNN image 사이의 feature relationship을 distill하기 위한 segmentation head 학습 (KNN corr.)
   3) image와 random other image 사이의 feature relationship을 distill하기 위한 segmentation head 학습 (Random Image corr.)

-  self와 KNN correspondence loss → positive, attractive signal
   random image pairs → negative, repulsive signal

-  STEGO 구성

   -  learning feedback의 source이자, distilled feature를 예측하기 위한 segmentation head의 입력 역할을 하는 frozen backbone으로 구성
   -  segmentation head $\Rightarrow$ ReLU activation을 가진 간단한 feed forward network

-  STEGO는 다른 연구와 다르게 재학습이나 fine-tuning X

   -  V100 1장으로 2시간 이내에 학습 끝
      1. image → backbone → global average pooling (GAP) → global image features
      2. backbone의 feature space에서 cosine similarity에 따라 각 image의 KNN lookup table 구성
         - 각 training minibatch는 random image $x$와 random nearest images $x^{knn}$의 collection으로 구성
           <span style='color:red'>$x^{knn}$ → 각 image의  top 7 KNNs에서 무작위로 sampling</span>
           ramdom image인 $x^{rand}$를 무작위로 섞어 자기 자신과 일치하는 이미지가 없는지 확인하여 sample 추출

-  STEGO's full loss

   -  $$\mathcal L=\lambda_{self}\mathcal L_{corr}(x, x, b_{self}) + \lambda_{knn}\mathcal L_{corr}(x, x^{knn}, b_{knn}) + \lambda_{rand}\mathcal L_{corr}(x, x^{rand}, b_{rand})$$, (5)
      -  $\lambda$s: learning signal 균형 제어
         $b$s: positive, negative pressure의 비율 제어
      -  $\lambda$s 비율 - $\lambda_{self} \approx \lambda_{rand} \approx 2\lambda_{knn}$
      -  $b$는 dataset과 network에 따라 다름, 시스템이 positive와 negative force 사이의 대략적인 균형을 유지하는 것 목표
         -  평균 KNN feature similarity $\approx$ 0.3
            평균 random similarity $\approx$ 0.0
            위와 같이 유지되도록 $b$s 설정

-  CocoStuff, Cityscapes datasets → 많은 이미지가 feature 해상도 (40, 40)에서 해결하기 어려운 작은 물체들로 복잡하게 구성

   -  작은 물체 더 잘 처리하고 빠른 훈련시간을 유지하기 위해 KNN 전, training image 5-crop 수행
      -  효과? 이미지의 세부사항을 더 자세히 볼 수 있고 KNN 성능 ↑ $+$ 5배 더 많은 이미지에서 일치하는 KNN 찾을 수 있음

   ![image](https://github.com/sunjong5108/CAM-based_Flare_Removal_Network/assets/81843626/b4846e3b-b9b4-4a28-8a1f-68f54bbd8306)

-  STEGO의 마지막 단계: Clurstering, CRF

   -  Clurstering
      -  STEGO가 형성한 clear clurster를 추출하기 위해 cosine distance 기반의 minibatch K-means algorithm 적용
         -  STEGO의 continuous feature로부터 구체적인 class 할당 계산
   -  CRF
      -  clurstering 후 spatial resolution 향상시키기 위해 label 정제

 ###  Relation To Potts Models And Energy-Based Graph Optimization

- Ising model이란?

  ![image](https://github.com/sunjong5108/CAM-based_Flare_Removal_Network/assets/81843626/47b842e3-ab82-4eff-a228-acd77ae5eef3)

  - Ising model: 수많은 미시 요소들이 서로 상호작용하고 각 미시요소에 힘이 주어졌을 때 전체(거시)로 어떤 동작을 하는지 표현하는 모델
    - Ising model은 방향 X graph
      $G=(V, E)$
      $V$: Vertex의 집합 (Graph node), $E$: Edge의 집합

- 저자들이 STEGO 최적화 과정을 ising model로 표현

  - $G=(V, w)$
    $|V|$ Verticeds에 대해 완전히 연결되고, wight(edges)가 있으며 방향이 없는 graph로 설정
  - $ω:V×V→ \mathbb R$ → edge weighting function <span style='color:red'>($F$; Feature correspondence)</span>
  - $∅:V→C$, parameterized neural network <span style='color:red'>($\mathcal S$; Segmentation head)</span>
    K 차원 continuous feature map을 code space C에 매핑
  - $μ:C×C→\mathbb R$
    두 code 비교하는데 드는 cost 측정하는 function <span style='color:red'>(cosine distance)</span>
  - $E(\phi):=\sum_{v_i, v_j \in \mathcal V}\omega(v_i, v_j)\mu(\phi(v_i),\phi(v_j))$, (6)
  - 볼츠만 분포로 표현
    $p(\phi|\omega, \mu)=\dfrac{exp(-E(\phi))}{\int_{\Phi}exp(-E(\phi'))d\phi'}, (7)$
  - 증명과정
    ![image](https://github.com/sunjong5108/CAM-based_Flare_Removal_Network/assets/81843626/73f55e90-34cc-4c23-a85c-a6235e319b25)
    ![image](https://github.com/sunjong5108/CAM-based_Flare_Removal_Network/assets/81843626/d3e4d77b-aeca-402e-bb4d-373a1def0f56)


## Experimental results

### ![image](https://github.com/sunjong5108/CAM-based_Flare_Removal_Network/assets/81843626/3e7d91d8-9b95-416a-84c9-b9537e4c22ec)

![image](https://github.com/sunjong5108/CAM-based_Flare_Removal_Network/assets/81843626/496de6f9-b992-4f92-9346-62d86b7701b3)

<br/>

> **Reference** 
>
> [https://arxiv.org/abs/2203.08414](https://arxiv.org/abs/2203.08414) <br/>
>
> [https://annealing-cloud.com/en/knowledge/3.html](https://annealing-cloud.com/en/knowledge/3.html)

