---
key: jekyll-text-theme
title: 'AdaMAE 논문 정리'
excerpt: 'AdaMAE 논문 읽고 정리하기'
tags: [AI, Computer Vision, MAE, Paper, Self-supervised learning, Pre-training, ViT]
---

# AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders (CVPR 2023)

## Abstract

- MAE는 image, text, audio, video등 많은 데이터에서 일반화할 수 있는 representation을 학습
  어떻게? visible data token으로부터 masked input data를 재구성함으로써
- Video에 대한 MAE → random patch, tube, frame 기반 masking 전략에 의존 <span style='color:red'>(저자들이 제안한 방법 이전까지)</span>
- 그래서 저자들은 MAE를 위한 adaptive masking strategy (AdaMAE)를 제안
  $+$ AdaMAE는 end-to-end 학습이 가능함
- Adaptive masking strategy는 auxiliary sampling network를 사용해서 semantic context에 기반해 visible token들을 추출
  - auxiliary sampling network? 시공간 patch token에 대한 categorical distribution을 추정
  - Reconstruction error를 증가시키는 token은 강화학습의 policy gradient algorithm에 따라 보상을 받고 visible token으로 선택됨
  - AdaMAE는 high spatiotemporal information 영역에서 더 많은 token을 sampling하여 token의 95%를 마스킹할 수 있음
    - 메모리 요구 사항 ↓, 더 빠른 pre-train 가능


---

## Introduction

- self-supervised learning (SSL)의 목적?

  - downstream applications (classification, detection 등)을 위해 수많은 unlabeled data로부터 transferable representation을 학습하는 것
    <span style='color:red'>→ Pre-training: Downstream task들에서 성능 ↑, 수렴속도 ↑, robustness ↑, model overfitting ↓</span>

- MAE

  - token들 중 5 ~ 10% 정도의 token들 (visible tokens)이 ViT 통과
  - ViT를 통해 encoding된 visible token이 masked token에 대해 학습가능한 representation과 연결
  - shallow decoder transformer에 공급되어 masked patch를 재구성

- MAE의 mask sampling 기술

  - MAE의 성공에 중요한 요인
  - 이전방식들: Random patch, tube, frame, masking
  - Random patch sampling은 다른 방식에 비해 성능이 좋음
    - **그러나 모든 token이 동일한 정보를 가지고 있지 X → visible token을 선택하기 위해 uniform distribution를 가정하는 것은 적절하지 않음**
      <span style='color:red'>→ 이런 random masking strategies을 사용하면 visible token이 high information 영역이 아닌 중복되거나 low information 영역에서 sampling되므로 reconstruction이 부정확해질 수 있음</span> 
      무슨말? MAE가 meaningful representation을 학습하는데 방해

- 저자들은 MAE와 adaptive token sampling network를 동시에 최적화하는 adaptive sampling approach 제안

  ![image](https://user-images.githubusercontent.com/81843626/235977582-ba5067f5-1dcf-4935-ba28-eca5b52dcd1a.png)

  - 시공간 정보를 기반으로 patch 선택 (visible token)
  - auxiliary network를 사용하여 모든 input token에 대한 categorical distribution을 추정하고, 추정한 distribution에서 visible token을 sampling
  - sampling은 미분할 수 없는 연산이므로 adaptive token sampling network를 최적화하기 위한 auxiliary loss (<span style='color:red'>강화학습에서 영감</span>)제안

---

## Related works

### Reinforcement Learning

- RL을 위한 Policy gradient methods는 gradient descent에 의한 기대보상을 최대화하는 최적의 policies을 선택하는 것에 초점

- 저자들의 sampling network는 pre-training MAEs을 위한 informative visible token들을 sampling하기 위해 모든 token들에 걸쳐 categorical distribution을 학습한다.
  <span style='color:red'>→ gradient 계산을 위한 unbiased estimator로써 REINFORCE policy gradient method를 sampling network parameter들 ($\theta$)을 업데이트하기 위해 사용 </span>

  - sampling network $f_{\theta}$에 의해 추정된 probability density function이 각 parameter $\theta$ 에 대해 미분가능할 때, policy gradient을 구현하려면 action을 sampling하고 확률 $p(\cdot)$를 다음과 같이 계산해야함
    $$
    \triangle \theta = \alpha \cdot R \cdot \dfrac {\partial log\ p(a)}{\partial \theta}
    $$
    $R$: 보상, $p(a)$: action을 취했을 때 확률, $\alpha$: learning rate

    - AdaMAE의 경우
      - Sampling network에 의해 추정된 probability distribution에 기반해 mask sampling (action)
      - MAE로부터 masked token들을 재구성 (environment)
      - 기대보상을 계산하기 위해 reconstruction error를 활용 (reward)

---

## Method

### AdaMAE 구조

![image](https://user-images.githubusercontent.com/81843626/235982490-d145b825-7ef5-47bf-9091-63f6ca33b848.png)

- Tokenizer (ViT로 치면 PatchEmbed)
  - input video $V$ $(T \times C \times H \times W)$ → Tokenizer (크기 $(t \times C \times h \times w)$의 커널 $K$와 크기 $(t \times h \times w)$의 stride $S$, output channel이 $d$인 3D convolution layer) → $V$를 $X$로 정의된 dimension $d$의 $N$개 token들로 token화, 여기서 $N=\dfrac {T}{t} \times \dfrac {H}{h} \times \dfrac {W}{w}$ → fixed 3D periodic positional encoding scheme를 활용함으로써 positional information을 token들에 주입
- Adaptive Token Sampler
  - Tokenize에서 나온 token $X$가 주어졌을 때, <br/>
    $X$ - Multi-head Attention + linear layer + softmax activation → 모든 token에 대한 probability scores $P \in \mathbb R^N$<br/>
    $Z$ - $MHA(X);\ Z \in \mathbb R^{N \times d}$<br/>
    $P$ - $Softmax(Linear(Z)); P \in \mathbb R^N$
  - $P$에 $N$차원 categorical distribution $(p \sim Categorical(N,\ P))$를 할당하고 비복원으로 visible token indices의 set $I_v$를 뽑음
    → masked token indices의 set, $I_m=U-I_v$, $U$: 모든 indices의 집합
  - Sampling된 visible token의 수 $N_v$는 사전에 정의된 masking ratio $\rho \in (0,\ 1)$에 기반헤 계산됨
    $N_v = N \times (1-\rho)$ 
- Encoder
  - $X_v$(visible tokens) → ViT encoder → latent representation $F_v$
- Decoder
  - visible token representation $F_v$는 masked token에 대한 fixed learnable representation $f_m$과 연결
    $+$ 두 representation 모두 positional information이 더해짐 <span style='color:red'>(원래 순서로 되돌리는 것 대신)</span>
    → predictions $\hat V$를 얻기 위해 light-weight transformer decoder 통과

### Optimizing AdaMAE

- Masked reconstruction loss $\mathcal L_R$

  - Masked token의 예측값과 patch normalized ground-truth RGB 값 사이의 MSE loss 활용해 최적화
    $$
    \mathcal L_R(\phi)=\dfrac {1}{N-N_v} \sum_{i \in I_m} \rVert \hat V - \tilde V \rVert_2
    $$
    $\hat V$: predicted tokens, $\tilde V$: local patch normalized ground-truth RGB values

- Adaptive sampling loss $\mathcal L_s$

  - adaptive token sampling network → sampling loss $\mathcal L_s$를 활용해서 최적화<br/>
    <span style='color:red'>MAE와 무관하게 gradient update 가능</span>

  - $\mathcal L_s$, REINFORCE algorithm에서 영감을 얻음

    - visible token sampling process - action
    - MAE (ViT backbone과 decoder) - environment
    - masked reconstruction loss $\mathcal L_R$ - return

  - REINFORCE algorithm에서의 expected reward maximization에 따라 expected reconstruction error $\mathbb E(\mathcal L_R)$를 최대화시킴으로써 sampling network를 최적화
    ![image](https://user-images.githubusercontent.com/81843626/235991094-35337b3f-4b0d-4ddd-a29a-ff9d6973afa8.png)

  - Figure 3.를 통해 왜 adaptive sampling에서  $\mathbb E(\mathcal L_R)$을 최대화하는 것이 효과적인지 설명

    - high activity/information (춤추는 커플)
      low activity/information (배경)
    - Figure 3.의 세 번째 행 foreground 주변의 high reconstruction error관찰
    - objective
      - high activity region에서 더 많은 visible token을 sampling하고 background에서 더 적은 token을 sampling하는 것
        <span style='color:red'>→ masked token에 대해 expected reconstruction error를 최대화하여 sampling network를 최적화 ($\mathbb E(\mathcal L_R)$)</span> 
    - 위 rule로 최적화 → adaptive sampling network는 background의 token과 비교하여 high activity region의 token에 대해 high probability score 예측

  - MAE에 대한 이런 adaptive token sampling approach는 high activity region에 더 많은 sample를 할당하고 low activity region에 더 적은 sample을 할당하는 compressed sensing의 non-uniform sampling과 밀접하게 일치

  - adaptive sampling은 시공간 정보 수준에 따라 sample를 할당하기 때문에 token할당에 효율적잊 않은 random sampling에 비헤 동일한 reconstruction error를 달성하는데 더 적은 token이 필요
    $$
    \mathcal L_s(\theta) = -\mathbb E[\mathcal L_R(\phi)]=-\sum_{i \in I_m} p_\theta ^ i \cdot \mathcal L_R^i(\phi)
    $$
    <br/>위 식 - adaptive token sampling network 최적화를 위한 objective function<br/>
    $p_\theta^i$ - $\theta$로 parameter화 된 adaptive token sampling에서 추론한 index i에서 mask_token의 확률<br/>

    $\mathcal L_R^i$ - mask token의 reconstruction error<br/>

    $\mathcal L_R(\phi)$ - parameter $\phi$가 있는 MAE에서 발생하는 reconstruction error<br/>

    $+$ $\mathcal L_s({\phi})$ - gradient update가 MAE를 통해 전파되는 것을 방지

    - 작은 확률값으로 인한 precision error를 피하기 위해 확률에 log 취함, ' - '때문에 gradient descent  

<br/>

> **Reference** 
>
> [[2211.09120v1\] AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders (arxiv.org)](https://arxiv.org/abs/2211.09120v1)

